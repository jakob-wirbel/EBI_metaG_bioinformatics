---
title: "Comparative Metagenome Analysis - EBI Metagenomics 
        Bioinformatics - SOLUTIONS"
output:
  html_document:
    toc: yes
    toc_float: yes
    number_sections: yes
    keep_md: true
    df_print: paged
author: "Jakob Wirbel and Georg Zeller"
---

In this practical, we are going to explore statistical testing methods for 
metagenomic data, how to visualize the results, and how to train machine 
learning models using the `SIAMCAT` package.

> Please note that this document contains the solution to the exercises!

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE)
```

# Setup

## Preparing the R environment 

In order to get started, we should first prepare our `R` environment and load
the packages we will need later on. Additionally, the data used in this 
practical are stored on the EMBL servers and we can set the base path for the
downloads.

```{R prep, message=FALSE}
library("tidyverse") # for general data wrangling and plotting
library("SIAMCAT")   # for statistical and ML analyses

data.location <- 'https://embl.de/download/zeller/metaG_course/'
```

## Loading the Data

In this practical, we are going to have a look at the data from
[Zeller et al. _MSB_ 2014](https://doi.org/10.15252/msb.20145645). In this 
study, the authors recruited patients with **colorectal cancer (CRC)** 
and **healthy controls (CTR)** and performed shotgun metagenomic sequencing 
of fecal samples. The raw data have already been pre-processed and analyzed 
with the [mOTUs2](https://doi.org/10.1038/s41467-019-08844-4) taxonomic 
profiler.

### Features

First, we are going to load the taxonomic profiles and store them as a matrix.

```{R load_data, message=FALSE, warning=FALSE}
fn.feat.fr  <- paste0(data.location, '/motus_profiles/FR-CRC.motus')
tax.profiles <- read.table(fn.feat.fr, sep = '\t', quote = '', 
                           comment.char = '', skip = 61, 
                           stringsAsFactors = FALSE, check.names = FALSE, 
                           row.names = 1, header = TRUE)
tax.profiles <- as.matrix(tax.profiles)
```

The taxonomic profiles contain absolute counts and can easily be transformed
into relative abundances using the `prop.table` function:

```{R rel_ab}
rel.tax.profiles <- prop.table(tax.profiles, 2)
```

### Metadata

Additionally, we also need the information which sample belongs to which group.
Therefore, we are loading the metadata table as well:

```{R load_metadata, message=FALSE}
fn.meta.fr  <- paste0(data.location, '/metadata/meta_FR-CRC.tsv')
df.meta <- read_tsv(fn.meta.fr)
df.meta
table(df.meta$Group)
```

We are interested in the comparison between control samples (`CTR`) and 
colorectal cancer samples (`CRC`), so we first remove the other samples, 
which represent advanced adenoma (`ADA`) or non-advanced adenoma (`NAA`).
Also, we transform the metadata into a data.frame object (which is easier 
for some analyses later on).

```{r clean_metadata}
df.meta <- df.meta %>% 
  filter(Group %in% c('CRC', 'CTR')) %>% 
  as.data.frame()
rownames(df.meta) <- df.meta$Sample_ID

# restrict the taxonomic profiles to CRC and CTR samples
tax.profiles <- tax.profiles[,rownames(df.meta)]
rel.tax.profiles <- rel.tax.profiles[,rownames(df.meta)]
```

## Feature filtering

Currently, the matrix of taxonomic profiles contains `14213` different 
bacterial species. Of those, not all will be relevant for our question, since
some are present only in a handful of samples (low prevalence) or at extremely
low abundance. Therefore, it can make sense to filter your taxonomic profiles
before you begin the analysis. Here, we could for example use the maximum
species abundance as a filtering criterion. All species that have a relative
abundance of at least `1e-03` in at least one of the samples will be kept, 
the rest is filtered out. 


```{r filter_features}
species.max.value <- apply(rel.tax.profiles, 1, max)
f.idx <- which(species.max.value > 1e-03)
rel.tax.profiles.filt <- rel.tax.profiles[f.idx,]
```

Additionally, the mOTUs2 profiler can also estimate how much of the relative 
abundance cannot be classified. We also filter out this share of "Unknown".

```{r filter_features_2}
# unclassified are indicated by -1 in the mOTUs2 profiles
idx.um <- which(rownames(rel.tax.profiles.filt) == '-1')
rel.tax.profiles.filt <- rel.tax.profiles.filt[-idx.um,]
```


# Association Testing

Now that we have set up everyting, we can test all microbial species 
for statistically significant differences. In order to do so, we perform a 
Wilcoxon test on each individual bacterial species.

```{r assoc_testing}
p.vals <- rep_len(1, nrow(rel.tax.profiles.filt))
names(p.vals) <- rownames(rel.tax.profiles.filt)
stopifnot(all(rownames(df.meta) == colnames(rel.tax.profiles.filt)))
for (i in rownames(rel.tax.profiles.filt)){
  x <- rel.tax.profiles.filt[i,]
  y <- df.meta$Group
  t <- wilcox.test(x~y)
  p.vals[i] <- t$p.value
}
head(sort(p.vals))
```

The species with the most significant effect seems to be _Fusobacterium
nucleatum_, so let us take a look at the distribution of this species:

```{r, fuso}
species <- 'Fusobacterium nucleatum subsp. animalis [ref_mOTU_v25_01001]'
df.plot <- tibble(fuso=rel.tax.profiles.filt[species,],
                  label=df.meta$Group)
df.plot %>% 
  ggplot(aes(x=label, y=fuso)) + 
    geom_boxplot() + 
    xlab('') + 
    ylab('F. nucleatum rel. ab.')
```

Let us remember that log-scales are important when visualizing relative 
abundance data!

```{r fuso_2}
df.plot %>% 
  ggplot(aes(x=label, y=log10(fuso + 1e-05))) + 
    geom_boxplot(outlier.shape = NA) +
    geom_jitter(width = 0.08) + 
    xlab('') + 
    ylab('log10(F. nucleatum rel. ab.)')
```

# Exercises: Visualization 

## Solution I

**Explore the significantly associated species using boxplots or other 
visualization techniques. Which is the most strongly associated species that
is enriched in controls?**

There are several ways to complete this exercise and you are encouraged to be 
creative about how you solve it.

One way could be to plot several boxplots at the same time:

```{r solution_1}
spp <- names(head(sort(p.vals))) # look at the top 6 species

t(rel.tax.profiles.filt[spp,]) %>% 
  as_tibble(rownames = 'Sample_ID') %>% 
  left_join(df.meta %>% select(Sample_ID, Group)) %>% # join with metadata
  pivot_longer(cols = -c(Sample_ID, Group)) %>% 
  mutate(value=log10(value + 1e-05)) %>% # transform into log values
  mutate(name=factor(name, levels=spp)) %>% # change to factor for ordering
  ggplot(aes(x=name, y=value, fill=Group)) + 
    geom_boxplot() +
    xlab('') + 
    ylab('log10(rel.ab.)') + 
    theme(axis.text.x = element_text(angle=45, hjust=1))
```

It seems that the _Clostridium sp._ and _Eubacterium elgiens_ species are the 
top significant species enriched in controls.

## Solution II

**Plot a volcano plot of the associations between cancer and controls. Which
effect size could you use for the volcano plot?**

We can first try to compute the fold change as a measure for effect size and 
check how this would look like in a volcano plot. To do so, we loop again 
through all species:

```{r solution_2}
fc <- rep_len(NA, nrow(rel.tax.profiles.filt))
names(fc) <- rownames(rel.tax.profiles.filt)
stopifnot(all(rownames(df.meta) == colnames(rel.tax.profiles.filt)))
for (i in rownames(rel.tax.profiles.filt)){
  x <- rel.tax.profiles.filt[i,]
  y <- df.meta$Group
  x.ctr <- median(log10(x[y=='CTR'] + 1e-05))
  x.crc <- median(log10(x[y=='CRC'] + 1e-05))
  fc[i] <- x.crc-x.ctr
}
tail(sort(fc))
```

Now, we can plot the volcano plot:
```{r solution_2_2}
plot(fc, -log10(p.vals), 
     xlab='median fold change')
```

As you can see, there are a lot bacterial species that show a significant 
difference which is not captured by the standard median fold change. Therefore,
the generalized fold change (see the section below) will be more appriopriate
for microbiome data.

## Solution III

**Create a ordination plot for our data and colour the samples by group. 
How would you interpret the results? Try out different ecological distances. 
How does the choice of distance affect the group separation?**  
(**Tip**: make sure to check out the `vegdist` function in the **vegan** 
package and also the `pco` function in the **labdsv** package)

First, we can load the `vegan` and the `labdsv` packages:
```{r solution_3, message=FALSE}
library("vegan")
library("labdsv")
```

Then, we compute the ecological distances across samples using the `vegdist` 
function. By default, it will use the Bray-Curtis distance, but you can
play around with other distances as well.

```{r solution_3_2}
dist.mat <- vegdist(t(rel.tax.profiles.filt))
```

This distance matrix can be put directly into the `pco` function:
```{r solution_3_3}
pco.results <- pco(dist.mat)
```

Now we can extract the results and merge them with the metadata in order to
visualize the results. It also makes sense to include the information what
amount of variance is explained by the different axes in the PCO.

```{r solution_3_4, warning=FALSE}
# extract points
df.plot <- pco.results$points %>% 
  as_tibble(rownames = 'Sample_ID') %>% 
  left_join(df.meta)

# extract percentages of explained variance
percentage <- pco.results$eig[1:2]/sum(pco.results$eig)
percentage <- percentage*100
percentage <- paste0(sprintf(fmt='%.2f', percentage),'%')

df.plot %>% 
  ggplot(aes(x=V1, y=V2, col=Group)) + 
    geom_point() + 
    xlab(paste0('PCo1 [', percentage[1], ']')) + 
    ylab(paste0('PCo2 [', percentage[2], ']'))

```


# SIAMCAT Association Testing

We can also use the `SIAMCAT` R package to test for differential abundance and
produce standard visualizations.

```{r siamcat, message=FALSE}
library("SIAMCAT")
```

Within `SIAMCAT`, the data are stored in the `SIAMCAT` object which contains 
the feature matrix, the metadata, and information about the groups you want to
compare.

```{r sc.obj}
sc.obj <- siamcat(feat=rel.tax.profiles, meta=df.meta, 
                  label='Group', case='CRC')
```

We can use `SIAMCAT` for feature filtering as well:

```{r sc_filtering}
sc.obj <- filter.features(sc.obj, filter.method = 'abundance', cutoff = 1e-03)
sc.obj <- filter.features(sc.obj, filter.method = 'prevalence', 
                          cutoff = 0.05, feature.type = 'filtered')
sc.obj
```

Now, we can test the filtered feature for differential abundance with `SIAMCAT`:

```{r sc_assoc_testing, eval=FALSE}
sc.obj <- check.associations(sc.obj, detect.lim = 1e-05, 
                             fn.plot = './associations.pdf')
```
```{r sc_assoc_testing_real, message=FALSE, echo=FALSE}
sc.obj <- check.associations(sc.obj, detect.lim = 1e-05, 
                             panels = c('fc'),
                             prompt = FALSE)
```

The associations metrics computed by `SIAMCAT` are stored in the `SIAMCAT` 
object and can be extracted, if you want to have a closer look at the results
for yourself. For example, one could create a volcano plot like that:

```{r volc_2}
df.assoc <- associations(sc.obj)
df.assoc %>% 
  ggplot(aes(x=fc, y=-log10(p.adj))) + 
    geom_point() + 
    xlab('Fold change')

```


# Machine learning with SIAMCAT

## Machine learning workflow

The `SIAMCAT` machine learning workflow consists of several steps:

```{r diagrammr, echo=FALSE}
library(DiagrammeR)

grViz("
digraph siamcat_workflow {

  # a 'graph' statement
  graph [overlap = true, fontsize = 10]

  # several 'node' statements
  node [shape = box,
  fontname = Helvetica,
  label='filter.features']
  C

  node [shape = box,
  fontname = Helvetica,
  label='normalize.features']
  F

  node [shape = box,
  fontname = Helvetica,
  label='create.data.split']
  G

  node [shape = box,
  fontname = Helvetica,
  label='train.model']
  H

  node [shape = box,
  fontname = Helvetica,
  label='make.predictions']
  I

  node [shape = box,
  fontname = Helvetica,
  label='evaluate.prediction']
  J

  node [shape = box,
  fontname = Helvetica,
  label='model.evaluation.plot']
  K

  node [shape = box,
  fontname = Helvetica,
  label='model.interpretation.plot']
  L

  # several 'edge' statements
  C->F
  F->G G->H H->I I->J J->K
  J->L
  }
")

```

Since we already created a `SIAMCAT` object and filtered the raw data, we can
start directly with the next step.

## Normalization

`SIAMCAT` offers a few normalization approaches that can be useful for
subsequent statistical modeling in the sense that they transform features in
a way that can increase the accuracy of the resulting models. Importantly,
these normalization techniques do not make use of any label information
(patient status), and can thus be applied up front to the whole data set 
(and outside of the following cross validation).

```{r normalization}
sc.obj <- normalize.features(sc.obj, norm.method = 'log.std',
                             norm.param = list(log.n0=1e-05, sd.min.q=0))
sc.obj
```

## Cross validation split

Cross validation is a technique to assess how well an ML model would generalize 
to external data by partionining the dataset into training and test sets.
Here, we split the dataset into 10 parts and then train a model on 9 of these
parts and use the left-out part to test the model. The whole process is 
repeated 10 times.

```{r cv}
sc.obj <- create.data.split(sc.obj, num.folds = 10, num.resample = 10)
```


## Model Training

Now, we can train a
[LASSO logistic regression classifier](https://www.jstor.org/stable/2346178)
in order to distinguish CRC cases and controls.

```{r training}
sc.obj <- train.model(sc.obj, method='lasso')
```

## Predictions

This function will automatically apply the models trained in cross validation 
to their respective test sets and aggregate the predictions across the whole 
data set.

```{r predictions}
sc.obj <- make.predictions(sc.obj)
```

## Model Evaluation 

Calling the `evaluate.predictions` funtion will result in an assessment of
precision and recall as well as in ROC analysis, both of which can be plotted
as a pdf file using the `model.evaluation.plot` funtion (the name of/path to
the pdf file is passed as an argument).

```{r evaluate_predictions}
sc.obj <- evaluate.predictions(sc.obj)
model.evaluation.plot(sc.obj, fn.plot = './eval_plot.pdf')
```

![](./eval_plot.png)

## Model interpretation

Finally, the `model.interpretation.plot` function will plot characteristics 
of the models (i.e. model coefficients or feature importance) alongside the 
input data aiding in understanding how / why the model works (or not).

```{r interpreation_plot, eval=FALSE}
model.interpretation.plot(sc.obj, consens.thres = 0.7,
                          fn.plot = './interpretation_plot.pdf')
```

![](./interpretation_plot.png)


# Exercise: Prediction on external data

On the EMBL cluster, there is another dataset from a colorectal cancer 
metagenomic study. The study population was recruited in Austria, so you can
find the data under:
```{R at_set}
fn.feat.at <- paste0(data.location, '/motus_profiles/AT-CRC.motus')
fn.meta.at <- paste0(data.location, '/metadata/meta_AT-CRC.tsv')
```

## Solution I
## Solution I

**Apply the trained model on this dataset and check the model performance 
on the external dataset.**

First, we load the external data in the same way as we did for the French
dataset and create a `SIAMCAT` object:
```{r solution_4, message=FALSE}
# features
tax.at <- read.table(fn.feat.at, sep = '\t', quote = '', 
                     comment.char = '', skip = 61, 
                     stringsAsFactors = FALSE, check.names = FALSE, 
                     row.names = 1, header = TRUE)
tax.at <- as.matrix(tax.at)
rel.tax.at <- prop.table(tax.at, 2)

# metadata
df.meta.at <- read_tsv(fn.meta.at)
df.meta.at <- df.meta.at %>% 
  filter(Group %in% c('CRC', 'CTR')) %>% 
  as.data.frame()
rownames(df.meta.at) <- df.meta.at$Sample_ID
tax.at <- tax.at[,rownames(df.meta.at)]
rel.tax.at <- rel.tax.at[,rownames(df.meta.at)]
```
```{r solution_4_1}
sc.obj.at.ext <- siamcat(feat=rel.tax.at, meta=df.meta.at, 
                         label='Group', case='CRC')
```

We can use the `make.predictions` function from `SIAMCAT` to apply the trained
models on the external data:
```{r solution_4_2}
sc.obj.at.ext <- make.predictions(sc.obj, siamcat.holdout = sc.obj.at.ext)
```

Then, we can also evaluate the predictions and create a ROC curve:
```{r solution_4_3}
sc.obj.at.ext <- evaluate.predictions(sc.obj.at.ext)
model.evaluation.plot(training.set=sc.obj, validation.set=sc.obj.at.ext,
                      fn.plot = './eval_plot_transfer_fr_at.pdf')
```

![](./eval_plot_transfer_fr_at.png)

## Solution II

**Train a `SIAMCAT` model on the Austrian dataset and apply it to the French 
dataset. How does the model transfer on the external dataset compare between
the two datasets? Compare also the feature weights when training on the French
or Austrian dataset.**

We can run the complete `SIAMCAT` pipeline for the Austrian data quite easily:
```{r solution_5_1}
sc.obj.at <- siamcat(feat=rel.tax.at, meta=df.meta.at, 
                     label='Group', case='CRC')
sc.obj.at <- filter.features(sc.obj.at, 
                             filter.method = 'abundance', cutoff = 1e-03)
sc.obj.at <- filter.features(sc.obj.at, filter.method = 'prevalence', 
                             cutoff = 0.05, feature.type = 'filtered')
sc.obj.at <- normalize.features(sc.obj.at, norm.method = 'log.std',
                                norm.param = list(log.n0=1e-05, sd.min.q=0))
sc.obj.at <- create.data.split(sc.obj.at, num.folds = 10, num.resample = 10)
sc.obj.at <- train.model(sc.obj.at, method='lasso')
sc.obj.at <- make.predictions(sc.obj.at)
sc.obj.at <- evaluate.predictions(sc.obj.at)
```

Let us create a new `SIAMCAT` object for the French data (that does not contain
trained models already) and apply the trained Austrian model on this dataset:

```{r solution_5_2}
sc.obj.fr <- siamcat(feat=rel.tax.profiles, meta=df.meta, 
                     label='Group', case='CRC')
sc.obj.fr <- make.predictions(sc.obj.at, siamcat.holdout = sc.obj.fr)
sc.obj.fr <- evaluate.predictions(sc.obj.fr)
```

Finally, we can compare the model transfer again:
```{r solution_5_3}
model.evaluation.plot(training.set=sc.obj.at, validation.set=sc.obj.fr,
                      fn.plot = './eval_plot_transfer_at_fr.pdf')
```

![](./eval_plot_transfer_at_fr.png)

# Exercise: Taxonomic vs functional predictors

In addition to the taxonomic profiles, we also created functional profiles
for the French dataset. You can find it under:
```{R kegg data}
fn.feat.fr.kegg <- paste0(data.location, 
                          '/functional_profiles/KEGG_kos_FR-CRC.tsv')
```

## Solution I

**Explore the distribution of the functional data (abundance distribution, 
prevalence, etc.) and compare it to what you observe with the taxonomic 
profiles. Which filtering regime would make sense for functional data?**

First, we will load the data:
```{r solution_6}
func.profiles <- read.table(fn.feat.fr.kegg, sep='\t', 
                            stringsAsFactors = FALSE, 
                            check.names = FALSE, quote = '', row.names = 1,
                            header = TRUE)
func.profiles <- as.matrix(func.profiles)
func.profiles <- func.profiles[,df.meta$Sample_ID]
rel.func.profiles <- prop.table(func.profiles, 2)
```

Again, this question is a bit open-ended and invites you to explore the data. 
For example, you could look at the distribution of abundances:

```{r solution_6_2}
hist(log10(rel.func.profiles), 100, xlab='Relative abundance', 
     main='KEGG data', 
     col='slategrey')
hist(log10(rel.tax.profiles), 100, xlab='Relative abundance', 
     main='mOTUs data', 
     col='slategrey')
```

Also, the prevalence of the KEGG KOs could be interesting, especially when 
compared to the taxonomic abundance profiles

```{r solution_6_3}
prev.tax <- rowMeans(rel.tax.profiles != 0)
prev.func <- rowMeans(rel.func.profiles != 0)
hist(prev.tax, 50, col='slategrey', main='mOTUs data', xlab='Prevalence')
hist(prev.func, 50, col='slategrey', main='KEGG data', xlab='Prevalence')
```

Or we could look at the maximum abundance of the KEGG KOs (similarly to how
we filtered the taxonomic profiles above):

```{r solution_6_4}
func.max.value <- apply(rel.func.profiles, 1, max)
hist(log10(func.max.value), 100, col='slategrey', 
     xlab='Maximum relative abundance', main='KEGG data')
```

A good cutoff for filtering could for example be `1e-05`.

## Solution II

**Use `SIAMCAT` to train a model based on the functional KEGG profiles and 
compare it to the one trained on taxonomic profiles.**    
**Note** Since the functional profiles will have many thousands features,
it makes sense to perform feature selection on your dataset. You can 
supply the parameters for the feature selection to the `train.model` function
in `SIAMCAT`.

First, let us create a `SIAMCAT` object for the KEGG data
```{r solution_7}
sc.obj.kegg <- siamcat(feat = rel.func.profiles, meta=df.meta, 
                       label='Group', case='CRC')
# filter data
sc.obj.kegg <- filter.features(sc.obj.kegg, filter.method = 'abundance',
                               cutoff=1e-05)
sc.obj.kegg
```

Since there are still a lot of functions left after filtering, we can enforce
a feature selection scheme within the cross-validation so that the ML models
will trained only on a smaller subset of features. What this means is that in
every cross-validation fold, `SIAMCAT` will first compute the generalized fold
change (for the training data only) and then select the 200 features with the
highest absolute fold change value.

```{r solution_7_2}
sc.obj.kegg <- normalize.features(sc.obj.kegg, norm.method = 'log.std',
                                  norm.param = list(log.n0=1e-08, sd.min.q=0))
sc.obj.kegg <- create.data.split(sc.obj.kegg, num.folds = 10, num.resample = 10)
sc.obj.kegg <- train.model(sc.obj.kegg, method='lasso', perform.fs = TRUE,
                           param.fs = list(thres.fs=200, method.fs='gFC', 
                                           direction='absolute'))
sc.obj.kegg <- make.predictions(sc.obj.kegg)
sc.obj.kegg <- evaluate.predictions(sc.obj.kegg)
```

Finally, we can compare the KEGG model to the models based on mOTUs data

```{r solution_7_3}
model.evaluation.plot(mOTUs=sc.obj, KEGG=sc.obj.kegg,
                      fn.plot='./eval_plot_func.pdf')
```

![](./eval_plot_func.png)

# SessionInfo

```{R}
sessionInfo()
```